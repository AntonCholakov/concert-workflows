#!/usr/bin/env python3
"""
AWS Linux Security Bulletin Sync Script

This script scrapes Amazon Linux Security Advisory (ALAS) data from AWS websites
and can send the processed data to an API endpoint for security tracking.

Required parameters:
    --host: API host to send data to
    --batch-size: Number of records to process in each batch
    --api-key: API key for authentication

Optional parameters for troubleshooting:
    --auth-type: Authentication type (Bearer, Basic, or Token)
    --skip-ssl-verify: Skip SSL certificate verification
    --verbose: Enable verbose logging for debugging
"""

import json
import argparse
import logging
import sys
from pathlib import Path
from uuid import uuid4
from datetime import datetime
from typing import Dict, List, Optional, Set, Iterator
from dataclasses import dataclass

import requests
from bs4 import BeautifulSoup, Tag, PageElement

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('aws_bulletin_sync')

BASE_URL = 'https://alas.aws.amazon.com'
URLS = ['/index.html', '/alas2.html', '/alas2023.html']
OS_VERSION = {'index': '1', 'alas2': '2', 'alas2023': '2023'}
DATE_FORMAT = "%Y-%m-%d"


@dataclass
class Config:
    batch_size: int
    last_sync_timestamp: Optional[datetime]
    host: str
    port: int
    path: str
    instance_id: str
    api_key: str
    dry_run: bool
    output_file: Optional[Path]
    auth_type: str = "Bearer"
    skip_ssl_verify: bool = False


@dataclass
class AdvisoryRecord:
    id: str
    key: str
    cve: str
    advisory_recommender: str
    advisory: str
    product: str
    os_version: str
    advisory_payload: str
    severity: str
    cpe: str

    def to_dict(self) -> Dict[str, str]:
        return {
            'id': self.id,
            'key': self.key,
            'cve': self.cve,
            'advisory_recommender': self.advisory_recommender,
            'advisory': self.advisory,
            'product': self.product,
            'os_version': self.os_version,
            'advisory_payload': self.advisory_payload,
            'severity': self.severity,
            'cpe': self.cpe,
        }


def parse_arguments() -> Config:
    parser = argparse.ArgumentParser(
        description='Sync AWS Linux Security Bulletins',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument(
        '--batch-size',
        type=int,
        default=200,
        help='Number of records to process in each batch'
    )
    parser.add_argument(
        '--last-sync-timestamp',
        type=str,
        default=None,
        help='Last sync timestamp in format "YYYY-MM-DD"'
    )
    parser.add_argument(
        '--host',
        type=str,
        required=True,
        help='API host to send data to'
    )
    parser.add_argument(
        '--port',
        type=int,
        default=12443,
        help='API port'
    )
    parser.add_argument(
        '--path',
        type=str,
        default='/ingestion/api/v1/advisory/create',
        help='API path'
    )
    parser.add_argument(
        '--instance-id',
        type=str,
        default='0000-0000-0000-0000',
        help='Instance ID for API requests'
    )
    parser.add_argument(
        '--api-key',
        type=str,
        required=True,
        help='API key for authentication'
    )
    parser.add_argument(
        '--auth-type',
        type=str,
        default='C_API_KEY',
        choices=['C_API_KEY', 'Bearer', 'Basic', 'Token'],
        help='Authentication type to use with API key'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Only print the data without sending to API'
    )
    parser.add_argument(
        '--output-file',
        type=str,
        default=None,
        help='Save extracted data to a JSON file'
    )
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='Enable verbose logging'
    )
    parser.add_argument(
        '--skip-ssl-verify',
        action='store_true',
        help='Skip SSL certificate verification for API requests'
    )

    args = parser.parse_args()

    if args.verbose:
        logger.setLevel(logging.DEBUG)

    last_sync_timestamp = None
    if args.last_sync_timestamp:
        try:
            last_sync_timestamp = datetime.strptime(args.last_sync_timestamp, DATE_FORMAT)
        except ValueError:
            logger.error(f"Error: last_sync_timestamp should be in format '{DATE_FORMAT}'")
            parser.error(f"Invalid timestamp format. Please use '{DATE_FORMAT}'")

    output_file = Path(args.output_file) if args.output_file else None

    return Config(
        batch_size=args.batch_size,
        last_sync_timestamp=last_sync_timestamp,
        host=args.host,
        port=args.port,
        path=args.path,
        instance_id=args.instance_id,
        api_key=args.api_key,
        dry_run=args.dry_run,
        output_file=output_file,
        auth_type=args.auth_type,
        skip_ssl_verify=args.skip_ssl_verify
    )


def fetch_url(url: str) -> Optional[requests.Response]:
    try:
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        return response
    except requests.RequestException as e:
        logger.error(f"Error fetching {url}: {e}")
        return None


def extract() -> Dict[str, Tag]:
    logger.info("Extracting data from AWS Linux Security Bulletins...")
    contents = {}

    for url in URLS:
        full_url = BASE_URL + url
        logger.debug(f"Fetching {full_url}")
        response = fetch_url(full_url)

        if not response:
            logger.warning(f"Skipping {url} due to fetch error")
            continue

        soup = BeautifulSoup(response.text, features="html.parser")
        key = url.lstrip('/')[:-5]
        contents[key] = soup.body
        logger.debug(f"Successfully parsed {url}")

    return contents


def filter_text_nodes(nodes: Iterator[PageElement]) -> List[Tag]:
    return [node for node in nodes if isinstance(node, Tag)]


def parse_row(row: Tag, version_key: str, os_version_map: Dict[str, str]) -> List[AdvisoryRecord]:
    records = []
    os = 'amazonlinux'

    try:
        cells = filter_text_nodes(row.children)
        if len(cells) != 6:
            logger.debug(f"Skipping row with unexpected number of cells: {len(cells)}")
            return records

        created_text = cells[0].get_text().strip()
        updated_text = cells[1].get_text().strip()
        alas_id = cells[2].get_text().strip()
        severity = cells[3].get_text().strip()
        package = cells[4].get_text().strip()
        cves = cells[5].get_text().strip().split('\n')

        created_at = datetime.strptime(created_text, DATE_FORMAT)
        updated_at = datetime.strptime(updated_text, DATE_FORMAT)

        for cve in cves:
            if not cve.strip():
                continue

            index, body = alas_id.split('-', 1)
            versioned_alas = f"{index}{os_version_map[version_key]}-{body}"

            record = AdvisoryRecord(
                id=str(uuid4()),
                key=f"{cve}_OS_amazonlinux_{os_version_map[version_key]}",
                cve=cve,
                advisory_recommender=os,
                advisory=versioned_alas,
                product='amazon linux',
                os_version=os_version_map[version_key],
                advisory_payload='{}',
                severity=severity,
                cpe=''
            )
            records.append(record)

        return records
    except Exception as e:
        logger.debug(f"Error parsing row: {e}")
        return []


def transform(contents: Dict[str, Tag], last_sync_timestamp: Optional[datetime]) -> List[Dict[str, str]]:
    logger.info("Transforming data...")
    advisory_map: Dict[str, str] = {}
    records: List[AdvisoryRecord] = []
    processed_cves: Set[str] = set()

    for version_key, body in contents.items():
        if version_key not in OS_VERSION:
            logger.warning(f"Unknown version key: {version_key}, skipping")
            continue

        table = body.select_one('#ALAStable > tbody')
        if not table:
            logger.warning(f"No table found for {version_key}, skipping")
            continue

        rows = filter_text_nodes(table.children)
        logger.debug(f"Found {len(rows)} rows in {version_key} table")

        for row in rows:
            row_records = parse_row(row, version_key, OS_VERSION)

            if last_sync_timestamp:
                created_text = filter_text_nodes(row.children)[0].get_text().strip()
                created_at = datetime.strptime(created_text, DATE_FORMAT)

                if created_at < last_sync_timestamp:
                    logger.debug(f"Skipping record from {created_at} (before {last_sync_timestamp})")
                    continue

            for record in row_records:
                record_key = f"{record.cve}_{record.os_version}"
                if record_key not in processed_cves:
                    records.append(record)
                    processed_cves.add(record_key)

                    advisory_map[record.cve] = record.advisory

    return [record.to_dict() for record in records]


def save_to_file(data: List[Dict[str, str]], output_path: Path) -> None:
    try:
        with open(output_path, 'w') as f:
            # noinspection PyTypeChecker
            json.dump(data, f, indent=2)
        logger.info(f"Data saved to {output_path}")
    except Exception as e:
        logger.error(f"Error saving data to file: {e}")


def create_batches(data: List[Dict[str, str]], batch_size: int) -> List[List[Dict[str, str]]]:
    return [data[i:i + batch_size] for i in range(0, len(data), batch_size)]


def load(config: Config, data: List[Dict[str, str]]) -> None:
    if not data:
        logger.info("No data to load")
        return

    batches = create_batches(data, config.batch_size)
    logger.info(f"Preparing to load {len(data)} records in {len(batches)} batches")

    if config.dry_run:
        logger.info(f"DRY RUN: Would send {len(data)} records in {len(batches)} batches")
        if batches:
            logger.info(f"Sample data (first 2 records):")
            logger.info(json.dumps(batches[0][:2], indent=2))
        return

    if config.output_file:
        save_to_file(data, config.output_file)

    if not config.host:
        logger.warning("No host specified. Skipping API submission.")
        return

    error_count = 0
    max_errors = 3

    for i, batch in enumerate(batches):
        logger.info(f"Processing batch {i + 1}/{len(batches)} ({len(batch)} records)")

        headers = {
            "InstanceId": config.instance_id,
            "Content-Type": "application/json",
            "Authorization": f"{config.auth_type} {config.api_key}"
        }

        payload = {
            "advisories": batch
        }

        try:
            logger.debug(f"Sending request to https://{config.host}:{config.port}{config.path}")
            logger.debug(
                f"Headers: {json.dumps({k: v if k != 'Authorization' else '[REDACTED]' for k, v in headers.items()})}")

            response = requests.post(
                f"https://{config.host}:{config.port}{config.path}",
                headers=headers,
                json=payload,
                timeout=60,
                verify=not config.skip_ssl_verify
            )

            if response.status_code == 401:
                logger.error(
                    f"Authentication failed (401 Unauthorized). Please check your API key and authentication type.")
                logger.debug(f"Response: {response.text}")
                return

            response.raise_for_status()
            logger.info(f"Successfully sent batch {i + 1}")
            error_count = 0

        except requests.exceptions.SSLError as e:
            error_count += 1
            logger.error(f"Error sending batch {i + 1}: {e}")
            logger.warning("Try using --skip-ssl-verify to bypass SSL certificate verification")
            if error_count >= max_errors:
                logger.error(f"Stopping after {max_errors} consecutive SSL errors")
                return

        except requests.exceptions.HTTPError as e:
            error_count += 1
            logger.error(f"HTTP Error sending batch {i + 1}: {e}")
            logger.debug(f"Response content: {e.response.text if hasattr(e, 'response') else 'No response content'}")
            if error_count >= max_errors:
                logger.error(f"Stopping after {max_errors} consecutive HTTP errors")
                return

        except requests.exceptions.ConnectionError as e:
            error_count += 1
            logger.error(f"Connection Error sending batch {i + 1}: {e}")
            logger.warning("Check that the host is accessible and the port is correct")
            if error_count >= max_errors:
                logger.error(f"Stopping after {max_errors} consecutive connection errors")
                return

        except Exception as e:
            error_count += 1
            logger.error(f"Error sending batch {i + 1}: {e}")
            if error_count >= max_errors:
                logger.error(f"Stopping after {max_errors} consecutive errors")
                return


def main() -> None:
    try:
        config = parse_arguments()

        if config.skip_ssl_verify:
            import urllib3
            urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
            logger.info("SSL certificate verification disabled")

        contents = extract()
        if not contents:
            logger.error("No data extracted, exiting")
            return

        data = transform(contents, config.last_sync_timestamp)
        logger.info(f"Found {len(data)} records")

        load(config, data)

        logger.info("Sync completed successfully")
    except Exception as e:
        logger.error(f"Sync failed: {e}", exc_info=True)


if __name__ == "__main__":
    if len(sys.argv) == 1:
        print("AWS Linux Security Bulletin Sync Script\n")
        print("Example usage:")
        print(
            "  python aws_bulletin_sync.py --host example.com --batch-size 100 --api-key YOUR_API_KEY --skip-ssl-verify\n")
        print("For self-signed certificates, use the --skip-ssl-verify flag.")
        print("For more options, use --help")
        sys.exit(1)

    main()